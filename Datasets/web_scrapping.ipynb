{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (4.25.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: webdriver-manager in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from requests->webdriver-manager) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from requests->webdriver-manager) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from requests->webdriver-manager) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from requests->webdriver-manager) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting beautifulsoup4 (from bs4)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->bs4)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.12.3 bs4-0.0.2 soupsieve-2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install selenium\n",
    "%pip install webdriver-manager\n",
    "%pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import bs4\n",
    "import time\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.th-sl.com/search-by-word/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH, '/html/body/div[1]/section[2]/div/div/div/div/div/div/div/div[1]/div/div[2]/form/input[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.send_keys('ทะเล')\n",
    "search.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = driver.page_source\n",
    "soup = bs4.BeautifulSoup(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"document.body.style.zoom='100%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m word_list \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh1\u001b[39m\u001b[38;5;124m'\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melementor-post__title\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_list:\n\u001b[1;32m      3\u001b[0m     link \u001b[38;5;241m=\u001b[39m word\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'soup' is not defined"
     ]
    }
   ],
   "source": [
    "word_list = soup.find_all('h1',class_='elementor-post__title')\n",
    "for word in word_list:\n",
    "    link = word.find('a')\n",
    "    if link.text == 'ทะเล':\n",
    "        href_value = link['href']\n",
    "print(href_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.th-sl.com//wp-content/uploads/2020/09/5.43.2.mp4\n"
     ]
    }
   ],
   "source": [
    "driver.get(href_value)\n",
    "dowload_link = driver.find_element(By.XPATH, \"/html/body/div[2]/section[2]/div/div/div/section/div/div[1]/div/div/div/div/div[2]/video/a\")\n",
    "d_href_value = dowload_link.get_attribute('href')\n",
    "print(d_href_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เสร็จจ้า\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(d_href_value)\n",
    "with open('word.mp4', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "print(\"เสร็จจ้า\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list1 = [\n",
    "    'บ้าน', 'น้ำ', 'ดิน', 'ทะเล', 'ต้นไม้', 'ภูเขา', 'ปลา', 'แมว', 'หมา', 'รถ', 'หนังสือ', 'โรงเรียน',\n",
    "    'เด็ก', 'ครู', 'มือ', 'ข้าว', 'จาน', 'แก้ว', 'ช้อน', 'ชาม', 'เพื่อน', 'ครอบครัว', 'อาทิตย์',\n",
    "    'ดวงจันทร์', 'ดอกไม้', 'ทารก', 'ท้องฟ้า', 'ภาษาไทย', 'ภาษามือไทย', 'สัตว์', 'คอมพิวเตอร์',\n",
    "    'ผู้หญิง', 'ผู้ชาย', 'กลางวัน', 'กลางคืน', 'ของขวัญ', 'วันอาทิตย์', 'วันจันทร์', 'วันอังคาร',\n",
    "    'วันพุธ', 'วันพฤหัสบดี', 'วันศุกร์', 'วันเสาร์', 'แตงโม', 'อาหาร', 'ผลไม้', 'นม', 'รถ', 'คน', 'เสื้อ',\n",
    "    'ฉัน', 'เรา', 'คุณ', 'เขา', 'มัน', 'เธอ', 'กิน', 'ดื่ม', 'นอน', 'ตื่น', 'เดิน', 'วิ่ง', 'กระโดด', 'ขี่',\n",
    "    'ขับ', 'ล้าง', 'ทำ', 'อ่าน', 'เขียน', 'พูด', 'ฟัง', 'ดู', 'หัวเราะ', 'ร้องไห้', 'ยืน', 'นั่ง', 'ว่าย',\n",
    "    'ยิ้ม', 'เล่น', 'เปิด', 'ปิด', 'เป็น', 'อยู่', 'คือ', 'สวัสดี', 'ขอบคุณ', 'ขอโทษ', 'ลาก่อน', 'ได้โปรด',\n",
    "    'ใช่', 'ไม่ใช่', 'สบายดี', 'ทำไม', 'เมื่อไหร่', 'ที่ไหน', 'อย่างไร', 'ใคร', 'อะไร', 'ไม่เป็นไร', 'ยินดีด้วย'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = [\n",
    "     'น้ำแข็ง', 'ทะเล', 'ต้นไม้', 'ภูเขา', 'ปลา', 'แมว'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PINK = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   PURPLE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapping(words_list):\n",
    "    driver = webdriver.Chrome()\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "    for word in words_list:\n",
    "        driver.get('https://www.th-sl.com/search-by-word/')\n",
    "        time.sleep(3)\n",
    "\n",
    "        search = driver.find_element(By.XPATH, '/html/body/div[1]/section[2]/div/div/div/div/div/div/div/div[1]/div/div[2]/form/input[1]')\n",
    "        search.send_keys(word)\n",
    "        search.send_keys(Keys.ENTER)\n",
    "\n",
    "        time.sleep(4)\n",
    "\n",
    "        href_value = None\n",
    "        count = 2\n",
    "\n",
    "        while True:\n",
    "            data = driver.page_source\n",
    "            soup = bs4.BeautifulSoup(data, 'html.parser')\n",
    "            driver.execute_script(\"document.body.style.zoom='80%'\")\n",
    "\n",
    "            # Find the target elements\n",
    "            word_list = soup.find_all('h1', class_='elementor-post__title')\n",
    "            for target in word_list:\n",
    "                link = target.find('a')\n",
    "                if link and link.text.strip() == word:\n",
    "                    href_value = link['href']\n",
    "                    break\n",
    "            \n",
    "            if href_value:\n",
    "                print(f\"เจอคำว่า '{word}'\")\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                next_page_button = driver.find_element(By.XPATH, f'/html/body/div[1]/section[2]/div/div/div/div/div/nav/a[{count}]')\n",
    "                next_page_button.click()\n",
    "                print(f\"ไปหน้าต่อไป '{word}'\")\n",
    "                time.sleep(2)\n",
    "                count += 1\n",
    "            except :\n",
    "                print(f\"ไม่พบคำว่า {word}\")\n",
    "                break\n",
    "\n",
    "        if href_value:\n",
    "            driver.get(href_value)\n",
    "            time.sleep(2)\n",
    "\n",
    "            try:\n",
    "                download_link = wait.until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[2]/section[2]/div/div/div/section/div/div[1]/div/div/div/div/div[2]/video/a\")))\n",
    "                d_href_value = download_link.get_attribute('href')\n",
    "                \n",
    "                response = requests.get(d_href_value)\n",
    "\n",
    "                video_dir = f'VDO/{word}'\n",
    "                os.makedirs(video_dir, exist_ok=True)\n",
    "                file_path = f'{video_dir}/{word}_test.mp4'\n",
    "\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    print(f\"กำลังโหลดคำว่า '{word}'...\")\n",
    "                    f.write(response.content)\n",
    "                \n",
    "                print(f\"โหลด '{word}' เสร็จละจ้า\")\n",
    "                time.sleep(6)\n",
    "            except :\n",
    "                print(f\"ไม่เจอลิ้งโหลด '{word}'\")\n",
    "        else:\n",
    "            print(f\"ไม่เจอ href_value คำว่า '{word}'\")\n",
    "            \n",
    "        print('\\n')\n",
    "\n",
    "    driver.quit()\n",
    "    print('เสร็จหมดละเด้ออ')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เจอคำว่า 'น้ำแข็ง'\n",
      "กำลังโหลดคำว่า 'น้ำแข็ง'...\n",
      "โหลด 'น้ำแข็ง' เสร็จละจ้า\n",
      "เจอคำว่า 'ทะเล'\n",
      "กำลังโหลดคำว่า 'ทะเล'...\n",
      "โหลด 'ทะเล' เสร็จละจ้า\n",
      "เจอคำว่า 'ต้นไม้'\n",
      "กำลังโหลดคำว่า 'ต้นไม้'...\n",
      "โหลด 'ต้นไม้' เสร็จละจ้า\n",
      "เจอคำว่า 'ภูเขา'\n",
      "กำลังโหลดคำว่า 'ภูเขา'...\n",
      "โหลด 'ภูเขา' เสร็จละจ้า\n",
      "ไม่พบคำว่า ปลา\n",
      "ไม่พบ href_value สำหรับ 'ปลา'\n",
      "เจอคำว่า 'แมว'\n",
      "กำลังโหลดคำว่า 'แมว'...\n",
      "โหลด 'แมว' เสร็จละจ้า\n",
      "เสร็จหมดละเด้ออ\n"
     ]
    }
   ],
   "source": [
    "scrapping(words_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
