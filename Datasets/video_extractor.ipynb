{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Set Up & Import__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting numpy>=1.21.0 (from opencv-python)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-2.0.2 opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.15-cp39-cp39-macosx_11_0_universal2.whl.metadata (9.7 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting flatbuffers>=2.0 (from mediapipe)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.4.30-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.0 kB)\n",
      "Collecting matplotlib (from mediapipe)\n",
      "  Using cached matplotlib-3.9.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting numpy<2 (from mediapipe)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
      "  Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.0-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl.metadata (1.4 kB)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting ml-dtypes>=0.2.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.0-cp39-cp39-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Collecting opt-einsum (from jax->mediapipe)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting scipy>=1.9 (from jax->mediapipe)\n",
      "  Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from jax->mediapipe) (8.5.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->mediapipe)\n",
      "  Using cached fonttools-4.54.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (163 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib->mediapipe)\n",
      "  Using cached pillow-10.4.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->mediapipe)\n",
      "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Collecting importlib-resources>=3.2.0 (from matplotlib->mediapipe)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from importlib-metadata>=4.6->jax->mediapipe) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.15-cp39-cp39-macosx_11_0_universal2.whl (50.7 MB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached sounddevice-0.5.0-py3-none-macosx_10_6_x86_64.macosx_10_6_universal2.whl (107 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
      "Using cached jaxlib-0.4.30-cp39-cp39-macosx_11_0_arm64.whl (66.7 MB)\n",
      "Using cached matplotlib-3.9.2-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n",
      "Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (63.7 MB)\n",
      "Using cached cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.54.1-cp39-cp39-macosx_11_0_arm64.whl (2.3 MB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n",
      "Using cached ml_dtypes-0.5.0-cp39-cp39-macosx_10_9_universal2.whl (732 kB)\n",
      "Using cached pillow-10.4.0-cp39-cp39-macosx_11_0_arm64.whl (3.4 MB)\n",
      "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
      "Using cached scipy-1.13.1-cp39-cp39-macosx_12_0_arm64.whl (30.3 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: flatbuffers, pyparsing, pycparser, protobuf, pillow, opt-einsum, numpy, kiwisolver, importlib-resources, fonttools, cycler, attrs, absl-py, scipy, opencv-contrib-python, ml-dtypes, contourpy, CFFI, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed CFFI-1.17.1 absl-py-2.1.0 attrs-24.2.0 contourpy-1.3.0 cycler-0.12.1 flatbuffers-24.3.25 fonttools-4.54.1 importlib-resources-6.4.5 jax-0.4.30 jaxlib-0.4.30 kiwisolver-1.4.7 matplotlib-3.9.2 mediapipe-0.10.15 ml-dtypes-0.5.0 numpy-1.26.4 opencv-contrib-python-4.10.0.84 opt-einsum-3.4.0 pillow-10.4.0 protobuf-4.25.5 pycparser-2.22 pyparsing-3.1.4 scipy-1.13.1 sounddevice-0.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting plotly\n",
      "  Using cached plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: packaging in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from plotly) (24.1)\n",
      "Using cached plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.24.1 tenacity-9.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.3-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python\n",
    "%pip install mediapipe\n",
    "%pip install plotly\n",
    "%pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Color Class [ _Not Important_ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PINK = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   PURPLE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1728732267.217265  249357 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1728732267.373266  369771 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1728732267.392388  369770 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1728732267.395217  369774 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1728732267.395224  369773 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1728732267.395243  369776 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1728732267.400670  369770 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1728732267.410574  369774 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1728732267.413776  369776 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.1,\n",
    "    min_tracking_confidence=0.1\n",
    ")\n",
    "\n",
    "# Initializing the drawing utils for drawing the landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Define Needed Function__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract & Structerize Position From Each Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(hand_pos):\n",
    "    right, left, body, i = dict(), dict(), dict(), 0\n",
    "    if hand_pos[0] != None:\n",
    "        for data in hand_pos[0].landmark:\n",
    "            right['Landmark '+str(i)] = [data.x, data.y, data.z]\n",
    "            i+=1\n",
    "        i = 0\n",
    "    else:\n",
    "        right = None\n",
    "\n",
    "    if hand_pos[1] != None:\n",
    "        for data in hand_pos[1].landmark:\n",
    "            left['Landmark '+str(i)] = [data.x, data.y, data.z]\n",
    "            i+=1\n",
    "        i = 0\n",
    "    else:\n",
    "        left = None\n",
    "\n",
    "    if hand_pos[2] != None:\n",
    "        for data in hand_pos[2].landmark:\n",
    "            body['Landmark '+str(i)] = [data.x, data.y, data.z]\n",
    "            i+=1\n",
    "        i = 0\n",
    "    else:\n",
    "        body = None\n",
    "\n",
    "    hand_pos = {'Right': right, 'Left': left, 'Body': body}\n",
    "    hand_pos_df = pd.DataFrame(hand_pos).T\n",
    "    \n",
    "    return hand_pos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operate(mp_holistic,holistic_model, mp_drawing, file):    \n",
    "    vid = cv2.VideoCapture(file)\n",
    "    total_frame, total_capture = int(vid.get(cv2.CAP_PROP_FRAME_COUNT)), 0\n",
    "\n",
    "    for i in range(total_frame):\n",
    "        if i%(total_frame//30) == 0:\n",
    "            total_capture+=1\n",
    "        else:\n",
    "            continue\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "        vid.set(cv2.CAP_PROP_POS_FRAMES, (total_capture)*(total_frame/30))\n",
    "\n",
    "        if not ret or cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.flip(image,1)\n",
    "\n",
    "        image.flags.writeable = False\n",
    "        results = holistic_model.process(image)\n",
    "        image.flags.writeable = True\n",
    "    \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw Pose And Face Land Marks \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "        # Drawing Right hand Land Marks\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "        # Drawing Left hand Land Marks\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "        # Display the resulting image\n",
    "        cv2.imshow(\"Display\", image)\n",
    "\n",
    "        left= results.left_hand_landmarks\n",
    "        right = results.right_hand_landmarks\n",
    "        upper = results.pose_landmarks\n",
    "        hand_pos_df = extract_data([right, left, upper])\n",
    "        hand_pos_df.to_csv(\"test folder\"+'/Frame_'+str(total_capture-1)+'.csv')\n",
    "        print(\"\\r\"+\"Successfully captured frame:\", color.RED+color.BOLD+str(total_capture)+color.END+\" / 30\", end=\"\")\n",
    "        # print(\"Successfully captured frame:\", color.RED+color.BOLD+str(total_capture)+color.END+\" / 30\")\n",
    "\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\n\"+color.BOLD+color.GREEN+\"Done!\"+color.END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Using Zone__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1728732275.215580  369776 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "/Users/theerat/sign-language-translator/.venv/lib/python3.9/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "operate(mp_holistic,holistic_model, mp_drawing, 'fine1.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
